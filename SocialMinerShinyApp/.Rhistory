mergedDt <- mergedDfs[[11]]
#1.Original values of data:
#compute the cross-correlation plots and find the lag that gives the optimal correlation
ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues <- ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 20 * mean(mergedDtLm$x), y = mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = mean(mergedDtLm$x), y = mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 10 * mean(mergedDtLm$x), y = 5 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 1.1 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 4 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 3 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 2 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 2.2 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#Linear Regression with and without Twitter predictors
colnames(mergedDt) <- c("datetime","sensorV","twitterV")
sensTs <- ts(mergedDt$sensorV)
twitTs <- ts(mergedDt$twitterV)
alldata <- ts.intersect(sensTs,sensTslag1=lag(sensTs,-1), sensTslag2=lag(sensTs,-2),
twitTslag1=lag(twitTs,-1),
twitTslag10=lag(twitTs,-10),
twitTslag11=lag(twitTs,-11),
twitTslag12=lag(twitTs,-12),
twitTslag21=lag(twitTs,-21),
twitTslag22=lag(twitTs,-22),
twitTslag23=lag(twitTs,-23),
twitTslag24=lag(twitTs,-24),
)
tryit = lm(sensTs~twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,
data = alldata)
lmOut(tryit, file="tryit.csv")
tryit2 = lm(sensTs~sensTslag1+sensTslag2+twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,
data = alldata)
lmOut(tryit2, file="tryit2.csv")
tryit3 = lm(sensTs~sensTslag1+sensTslag2, data = alldata)
lmOut(tryit3, file="tryit3.csv")
head(alldata)
tryit2 = lm(sensTs~sensTslag1+sensTslag2+twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,data = alldata)
tryit = lm(sensTs~twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,
data = alldata)
lag(twitTs,-1)
#Linear Regression with and without Twitter predictors
colnames(mergedDt) <- c("datetime","sensorV","twitterV")
sensTs <- ts(mergedDt$sensorV)
twitTs <- ts(mergedDt$twitterV)
alldata <- ts.intersect(sensTs,sensTslag1=lag(sensTs,-1), sensTslag2=lag(sensTs,-2),
twitTslag1=lag(twitTs,-1),
twitTslag10=lag(twitTs,-10),
twitTslag11=lag(twitTs,-11),
twitTslag12=lag(twitTs,-12),
twitTslag21=lag(twitTs,-21),
twitTslag22=lag(twitTs,-22),
twitTslag23=lag(twitTs,-23),
twitTslag24=lag(twitTs,-24)
)
head(alldata)
mergedDt <- mergedDfs[[11]]
#1.Original values of data:
#compute the cross-correlation plots and find the lag that gives the optimal correlation
ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues <- ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues
#Linear Regression with and without Twitter predictors
colnames(mergedDt) <- c("datetime","sensorV","twitterV")
sensTs <- ts(mergedDt$sensorV)
twitTs <- ts(mergedDt$twitterV)
alldata <- ts.intersect(sensTs,sensTslag1=lag(sensTs,-1), sensTslag2=lag(sensTs,-2),
twitTslag1=lag(twitTs,-1),
twitTslag10=lag(twitTs,-10),
twitTslag11=lag(twitTs,-11),
twitTslag12=lag(twitTs,-12),
twitTslag21=lag(twitTs,-21),
twitTslag22=lag(twitTs,-22),
twitTslag23=lag(twitTs,-23),
twitTslag24=lag(twitTs,-24)
)
tryit = lm(sensTs~twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,
data = alldata)
lmOut(tryit, file="tryit.csv")
tryit2 = lm(sensTs~sensTslag1+sensTslag2+twitTslag1+twitTslag10+twitTslag11+twitTslag12+twitTslag21+twitTslag22+twitTslag23+twitTslag24,data = alldata)
lmOut(tryit2, file="tryit2.csv")
tryit3 = lm(sensTs~sensTslag1+sensTslag2, data = alldata)
lmOut(tryit3, file="tryit3.csv")
mergedDt <- mergedDfs[[12]]
#1.Original values of data:
#compute the cross-correlation plots and find the lag that gives the optimal correlation
ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues <- ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 2.2 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 0.8 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly flow means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 0.6 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
#plot scatter plots of twitter vs sensor
mergedDtLm <- mergedDt[,c(2,3)]
colnames(mergedDtLm) <- c("y","x")
p <- ggplot(mergedDtLm, aes(x=x, y=y)) +
geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
geom_point(shape=20, size = 5) +
xlab("Hourly mentions of Twitter events") +
ylab("Hourly speed means") +
#scale_y_discrete(breaks = seq(min(pol_dist$volume), max(pol_dist$volume), by = 100), labels = comma) +
ggtitle("Twitter Traffic Events VS Sensor Speed Readings") +
theme(plot.title = element_text(color="#666666", face="bold", size=14),
axis.text.x=element_text(size=14),
axis.text.y=element_text(size=14),
axis.title.x=element_text(size=14,face="bold"),
axis.title.y=element_text(size=14,face="bold")) +
geom_text(x = 5 * mean(mergedDtLm$x), y = 0.6 * mean(mergedDtLm$y),
label = lm_eqn(mergedDtLm), size=8, colour = "black", parse = TRUE)
print(p)
ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues <- ccf(mergedDt$value.y, mergedDt$value.x, ylab = "cross-correlation")
ccfvalues
#Linear Regression with and without Twitter predictors
colnames(mergedDt) <- c("datetime","sensorV","twitterV")
sensTs <- ts(mergedDt$sensorV)
twitTs <- ts(mergedDt$twitterV)
alldata <- ts.intersect(sensTs,sensTslag1=lag(sensTs,-1), sensTslag2=lag(sensTs,-2),
twitTslag7=lag(twitTs,-7),
twitTslag8=lag(twitTs,-8),
twitTslag9=lag(twitTs,-9)
#                      twitTslag12=lag(twitTs,-12),
#                      twitTslag21=lag(twitTs,-21),
#                      twitTslag22=lag(twitTs,-22),
#                      twitTslag23=lag(twitTs,-23),
#                      twitTslag24=lag(twitTs,-24)
)
tryit = lm(sensTs~twitTslag7+twitTslag8+twitTslag9,data = alldata)
lmOut(tryit, file="tryit.csv")
tryit2 = lm(sensTs~sensTslag1+sensTslag2+twitTslag7+twitTslag8+twitTslag9,data = alldata)
lmOut(tryit2, file="tryit2.csv")
tryit3 = lm(sensTs~sensTslag1+sensTslag2, data = alldata)
lmOut(tryit3, file="tryit3.csv")
75 + 112 + 301
600 + 1131 + 1185
dataDir
#Load the sensor data sets
sensors_full_filenames <- list.dirs(dataDir,full.names=TRUE)
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorDfs <- list()
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
mType <- unlist(strsplit(namePart, "_"))[3]
data <- read.table(file = sensors_full_filenames[i], sep = " ", header = FALSE, fileEncoding = "utf8")
colnames(data) <- c("datetime","V")
data$datetime <- strptime(data$datetime, format = "%Y-%m-%dT%H:%M:%S") - 3600
attr(data$datetime, "tzone") <- "GMT"
data <- data[with(data, order(datetime)), ]
data <- data[with(data, data$datetime >= "2016-04-13 00:00:00"),]
end_records <- nrow(data[with(data, data$datetime >= "2016-05-05 00:00:00"),])
if (end_records > 0) {
data <- data[with(data, data$datetime < "2016-06-22 00:00:00"),]
} else {
data <- data[with(data, data$datetime < "2016-05-04 00:00:00"),]
}
startDt <- min(data$datetime)
endDt <- max(data$datetime)
numMeasurement <- nrow(data)
sumtabDf <- rbind(sumtabDf, data.frame(
highway = highway,
mId = mId,
mType = mType,
startDt = strftime(startDt, format = "%Y-%m-%dT%H:%M:%S"),
endDt = strftime(endDt, format = "%Y-%m-%dT%H:%M:%S"),
numMeasurement = numMeasurement,
stringsAsFactors = F ))
sensorDfs[[i]] <- data
}
colnames(sumtabDf) <- c("Highway","Measurement Id","Measurement Type","Start DateTime","End DateTime","No of measurements")
kable(sumtabDf, format = "markdown", caption = "Sensor Data Sets")
mergedDfs <- list()
for (i in 1: length(sensorDfs)) {
print(kable(sumtabDf[i,c(2,1,3)], format = "markdown", caption = "Sensor Data Set"))
#aggregate sensor data
sensorDf <- sensorDfs[[i]]
highway <- sumtabDf$Highway[i]
mType <- sumtabDf$mType[i]
sensor.ts <- xts(sensorDf[,-1], order.by=as.POSIXct(sensorDf$datetime))
aggs.ts <- period.apply(sensor.ts, endpoints(sensor.ts, "hours"), function(x) mean(x))
aggs.tsAvgAggs = data.frame(
datetime = as.POSIXct(index(aggs.ts)) - 3540,
value = aggs.ts[,c(1)],
stringsAsFactors = F
)
aggs.tsAvgAggs$datetime <- aggs.tsAvgAggs$datetime
row.names(aggs.tsAvgAggs) <- NULL
minDate <- min(aggs.tsAvgAggs$datetime)
maxDate <- max(aggs.tsAvgAggs$datetime)
#retrieve the highway mentions aggs for the same road
#create dataframe to store the data
highwayTwitterAggs = data.frame(
gmt_date = as.POSIXct(character()),
value = numeric(0),
stringsAsFactors = F
)
#connect to mongoDB
mongo <- mongo.create(host = "optimum.euprojects.net:3368")
if (mongo.is.connected(mongo) == TRUE) {
queryList <- mongo.bson.from.list(
list('gmt_date' = list(
"$gte" = minDate,
"$lte" = maxDate
),
"highway_code" = highway))
tweets_count <- mongo.count(mongo,"Twitter.uk_accounts_highway_hr_agg",query=queryList)
if (tweets_count > 0) {
flog.info("Total records to be fetched for %s from %s to %s: %s", highway, minDate, maxDate, tweets_count)
result <- mongo.find(mongo, "Twitter.uk_accounts_highway_hr_agg", query = queryList)
while (mongo.cursor.next(result)) {
tdDt <- .POSIXct(character())
l <- list(mongo.bson.to.list(mongo.cursor.value(result)))
tdDt <- l[[1]]$gmt_date
value <- l[[1]]$value
highwayTwitterAggs <-rbind(highwayTwitterAggs,
data.frame(gmt_date = tdDt,
value = value,
stringsAsFactors = FALSE)
)
}
attr(highwayTwitterAggs$gmt_date, "tzone") <- "GMT"
highwayTwitterAggs <- highwayTwitterAggs[with(highwayTwitterAggs, order(gmt_date)), ]
} else {
flog.info("No records found from twitter for highway %s from %s to %s", highway, minDate, maxDate)
next
}
}
#fill the unavailable twitter dataset hours with zeros
highwayTwitterAggsFull <- data.frame(
gmt_date = as.POSIXct(character()),
value = numeric(0),
stringsAsFactors = F
)
minDateTwit <- minDate
maxDateTwit <- maxDate
while (minDateTwit <= maxDateTwit) {
value <- highwayTwitterAggs[highwayTwitterAggs$gmt_date == minDateTwit,c("value")]
if (length(value) > 0) {
highwayTwitterAggsFull <-rbind(highwayTwitterAggsFull,
data.frame(gmt_date = minDateTwit,
value = value,
stringsAsFactors = FALSE)
)
} else {
#flog.info("No record found in gmt_date: %s", strftime(minDateTwit,"%Y-%m-%d %H:%M:%S",tz="GMT"))
highwayTwitterAggsFull <-rbind(highwayTwitterAggsFull,
data.frame(gmt_date = minDateTwit,
value = 0,
stringsAsFactors = FALSE)
)
}
minDateTwit <- minDateTwit + 3600
}
attr(highwayTwitterAggsFull$gmt_date, "tzone") <- "GMT"
# highwayTwitterAggsFull$value <- na.approx(highwayTwitterAggsFull$value, x = index(highwayTwitterAggsFull$gmt_date), na.rm = TRUE, maxgap = Inf)
#merge the 2 datasets
mergedDt <- merge(aggs.tsAvgAggs, highwayTwitterAggsFull, by.x = "datetime", by.y = "gmt_date")
mergedDfs[[i]] <- mergedDt
}
setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
install.packages("astsa", dependencies = T)
install.packages("astsa", dependencies = T)
require(astsa)
citation("astsa")
installed.packages()[,1:3]
plot(jj, type="o", ylab="Quarterly Earnings per Share")
84 / 4
plot(gtemp, type="o", ylab="Global Temperature Deviations")
plot(speech)
plot(nyse, ylab="NYSE Returns")#
par(mfrow = c(2,1))  # set up the graphics
plot(soi, ylab="", xlab="", main="Southern Oscillation Index")
plot(rec, ylab="", xlab="", main="Recruitment")
par(mfrow=c(2,1), mar=c(3,2,1,0)+.5, mgp=c(1.6,.6,0))
ts.plot(fmri1[,2:5], lty=c(1,2,4,5), ylab="BOLD", xlab="", main="Cortex")
ts.plot(fmri1[,6:9], lty=c(1,2,4,5), ylab="BOLD", xlab="", main="Thalamus & Cerebellum")
mtext("Time (1 pt = 2 sec)", side=1, line=2)
par(mfrow=c(2,1))
plot(EQ5, main="Earthquake")
plot(EXP6, main="Explosion")
acf(speech, 250)
class(speech)
head(speech)
acfspeech <- acf(speech, 250)
class(acfspeech)
head(acfspeech)
acfspeech
par(mfrow=c(3,1))
acf(soi, 48, main="Southern Oscillation Index")
acf(rec, 48, main="Recruitment")
ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
?acf2
?acf
acfsoi <- acf(soi, 48, main="Southern Oscillation Index")
acfsoi
acfsoi <- acf(soi, 23, main="Southern Oscillation Index")
acfsoi <- acf(soi, 24, main="Southern Oscillation Index")
acfsoi
ccfsoirec <- ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
ccfsoirec
par(mfrow=c(3,1))
acf(soi, 48, main="Southern Oscillation Index")
acf(rec, 48, main="Recruitment")
ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
ccfsoirec <- ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
ccfsoirec
ccfsoirec <- ccf(soi, rec)
ccfsoirec
par(mfrow=c(1,1))
ccfsoirec <- ccf(soi, rec)
ccfsoirec
par(mfrow=c(3,1))
acf(soi, 48, main="Southern Oscillation Index")
acf(rec, 48, main="Recruitment")
ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
