grepl("\\<delays\\>", "delay detected in the roads", ignore.case = TRUE)
grepl("\\<delays\\>", "vfdelays detected in the roads", ignore.case = TRUE)
grepl("\\<delays\\>", "severe delays detected in the roads", ignore.case = TRUE)
grepl("\\<delays\\>", "severe delay detected in the roads", ignore.case = TRUE)
750 / (750 + 2167)
750 / (1407)
90 / (90 + 2238)
90 / (92)
703 / (703 + 300)
703 / (4749)
1244 / (1244 + 759)
1244 / (1407)
4013 / (4013 + 231)
4013 / (4749)
shiny::runApp('C:/Users/Ahmad/Dropbox/Work/WolverhamptonUni/Optimum/social_media/twitter/SocialMinerShinyApp')
4749 / 6248 * 100
1407 / 6248 * 100
92 / 6248 * 100
2238 / 6248
2167 / 6248
(4513 + 91 + 943) / 6248
shiny::runApp('C:/Users/Ahmad/Dropbox/Work/WolverhamptonUni/Optimum/social_media/twitter/SocialMinerShinyApp')
require(astsa)
par(mfrow = c(2,1))  # set up the graphics
plot(soi, ylab="", xlab="", main="Southern Oscillation Index")
plot(rec, ylab="", xlab="", main="Recruitment")
par(mfrow=c(3,1))
acf(soi, 48, main="Southern Oscillation Index")
acf(rec, 48, main="Recruitment")
ccf(soi, rec, 48, main="SOI vs Recruitment", ylab="CCF")
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
x=scan("quakes.dat")
x=ts(x) #this makes sure R knows that x is a time series
plot(x, type="b") #time series plot of x with points marked as “o”
?scan
x=read.table(file = "quakes.dat", sep = " ", header = T, fileEncoding = "utf8")
x=read.table(file = "quakes.dat", sep = " ", header = T, fileEncoding = "utf8")
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
#x=scan("quakes.dat")
x=read.table(file = "quakes.dat", sep = " ", header = T, fileEncoding = "utf8")
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
#x=scan("quakes.dat")
x=read.table(file = "quakes.dat", sep = "", header = T, na.strings ="", stringsAsFactors= F)
head(x)
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
#x=scan("quakes.dat")
xDF=read.table(file = "quakes.dat", sep = "", header = T, na.strings ="", stringsAsFactors= F)
x=ts(sDF$MAG) #this makes sure R knows that x is a time series
plot(x, type="b") #time series plot of x with points marked as “o”
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
#x=scan("quakes.dat")
xDF=read.table(file = "quakes.dat", sep = "", header = T, na.strings ="", stringsAsFactors= F)
x=ts(xDF$MAG) #this makes sure R knows that x is a time series
plot(x, type="b") #time series plot of x with points marked as “o”
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
#x=scan("quakes.dat")
xDF=read.table(file = "quakes.dat", sep = "", header = T, na.strings ="", stringsAsFactors= F)
x=ts(xDF$MAG) #this makes sure R knows that x is a time series
par(mfrow = c(1,1))
plot(x, type="b") #time series plot of x with points marked as “o”
library(astsa) # See note 1 below
lag1.plot(x,1) # Plots x versus lag 1 of x.
acf(x, xlim=c(1,19)) # Plots the ACF of x for lags 1 to 19
xlag1=lag(x,-1) # Creates a lag 1 of x variable. See note 2
y=cbind(x,xlag1) # See note 3 below
ar1fit=lm(y[,1]~y[,2])#Does regression, stores results object named ar1fit
summary(ar1fit) # This lists the regression results
plot(ar1fit$fit,ar1fit$residuals) #plot of residuals versus fits
acf(ar1fit$residuals, xlim=c(1,18)) # ACF of the residuals for lags 1 to 18
ar1fit
head(y)
names(cmort)
names(quakes)
length(quakes$mag)
setwd("C:\\Users\\Ahmad\\Dropbox\\PD\\Applied Time Series Analysis - STAT 510\\quakes")
# xDF=read.table(file = "quakes.dat", sep = "", header = T, na.strings ="", stringsAsFactors= F)
x=ts(quakes$mag) #this makes sure R knows that x is a time series
par(mfrow = c(1,1))
plot(x, type="b") #time series plot of x with points marked as “o”
library(astsa) # See note 1 below
lag1.plot(x,1) # Plots x versus lag 1 of x.
acf(x, xlim=c(1,19)) # Plots the ACF of x for lags 1 to 19
xlag1=lag(x,-1) # Creates a lag 1 of x variable. To lag back in time in R, use a negative lag.
y=cbind(x,xlag1)
ar1fit=lm(y[,1]~y[,2])#Does regression, stores results object named ar1fit
summary(ar1fit) # This lists the regression results
plot(ar1fit$fit,ar1fit$residuals) #plot of residuals versus fits
acf(ar1fit$residuals, xlim=c(1,18)) # ACF of the residuals for lags 1 to 18
plot(mort, type="o") # plot of mortality rate
plot(cmort, type="o") # plot of mortality rate
mort=ts(mort)
mortdiff=diff(mort,1) # creates a variable = x(t) – x(t-1)
plot(mortdiff,type="o") # plot of first differences
mort=ts(cmort)
mortdiff=diff(cmort,1) # creates a variable = x(t) – x(t-1)
plot(mortdiff,type="o")
acf(mortdiff,xlim=c(1,24))
head(mortdiff)
mort=ts(cmort)
mortdiff=diff(mort,1) #
plot(mortdiff,type="o")
acf(mortdiff,xlim=c(1,24))
mortdifflag1=lag(mortdiff,-1)
y=cbind(mortdiff,mortdifflag1) # bind first differences and lagged first differences
mortdiffar1=lm(y[,1]~y[,2]) # AR(1) regression for first differences
summary(mortdiffar1) # re
acf(mortdiffar1$residuals, xlim = c(1,24)) # ACF of residuals for 24 lags.
Sys.setenv(TZ='GMT')
setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
list.dirs <- function(path, pattern=NULL, all.dirs=FALSE, full.names=TRUE, ignore.case=FALSE) {
# use full.names=TRUE to pass to file.info
all <- list.files(path, pattern, all.dirs,
full.names=TRUE, recursive=FALSE, ignore.case=TRUE)
# determine whether to return full names or just dir names
if(isTRUE(full.names))
return(all)
else
return(basename(all))
}
#sensor data directory
dataDir <- "NTISData\\"
GetRoadAndSensorNames <- function() {
#Load the sensor data sets
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorVec <- character(0)
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
name <- paste0(highway,"_",highway)
sensorVec <- c(sensorVec,name)
}
}
GetRoadAndSensorNames()
Sys.setenv(TZ='GMT')
setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
list.dirs <- function(path, pattern=NULL, all.dirs=FALSE, full.names=TRUE, ignore.case=FALSE) {
# use full.names=TRUE to pass to file.info
all <- list.files(path, pattern, all.dirs,
full.names=TRUE, recursive=FALSE, ignore.case=TRUE)
# determine whether to return full names or just dir names
if(isTRUE(full.names))
return(all)
else
return(basename(all))
}
#sensor data directory
dataDir <- "NTISData\\"
GetRoadAndSensorNames <- function() {
#Load the sensor data sets
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorVec <- character(0)
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
name <- paste0(highway,"_",highway)
sensorVec <- c(sensorVec,name)
}
return(sensorVec)
}
GetRoadAndSensorNames()
Sys.setenv(TZ='GMT')
setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
list.dirs <- function(path, pattern=NULL, all.dirs=FALSE, full.names=TRUE, ignore.case=FALSE) {
# use full.names=TRUE to pass to file.info
all <- list.files(path, pattern, all.dirs,
full.names=TRUE, recursive=FALSE, ignore.case=TRUE)
# determine whether to return full names or just dir names
if(isTRUE(full.names))
return(all)
else
return(basename(all))
}
#sensor data directory
dataDir <- "NTISData\\"
GetRoadAndSensorNames <- function() {
#Load the sensor data sets
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorVec <- character(0)
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
name <- paste0(highway,"_",mId)
name <- unique(name)
name <- sort(name)
sensorVec <- c(sensorVec,name)
}
return(sensorVec)
}
GetRoadAndSensorNames()
shiny::runApp()
Sys.setenv(TZ='GMT')
# setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
list.dirs <- function(path, pattern=NULL, all.dirs=FALSE, full.names=TRUE, ignore.case=FALSE) {
# use full.names=TRUE to pass to file.info
all <- list.files(path, pattern, all.dirs,
full.names=TRUE, recursive=FALSE, ignore.case=TRUE)
# determine whether to return full names or just dir names
if(isTRUE(full.names))
return(all)
else
return(basename(all))
}
#sensor data directory
dataDir <- "NTISData\\"
GetRoadAndSensorNames <- function() {
#Load the sensor data sets
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorVec <- character(0)
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
name <- paste0(highway,"_",mId)
name <- unique(name)
name <- sort(name)
sensorVec <- c(sensorVec,name)
}
return(sensorVec)
}
GetRoadAndSensorNames()
?selectInput
shiny::runApp()
shiny::runApp()
sort(c("fg","ac"))
Sys.setenv(TZ='GMT')
# setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
list.dirs <- function(path, pattern=NULL, all.dirs=FALSE, full.names=TRUE, ignore.case=FALSE) {
# use full.names=TRUE to pass to file.info
all <- list.files(path, pattern, all.dirs,
full.names=TRUE, recursive=FALSE, ignore.case=TRUE)
# determine whether to return full names or just dir names
if(isTRUE(full.names))
return(all)
else
return(basename(all))
}
#sensor data directory
dataDir <- "NTISData\\"
GetRoadAndSensorNames <- function() {
#Load the sensor data sets
sensors_filenames <- list.dirs(dataDir,full.names=FALSE)
sensorVec <- character(0)
sumtabDf <- data.frame(
highway = character(0),
mId = character(0),
mType = character(0),
startDt = as.POSIXct(character()),
endDt = as.POSIXct(character()),
numMeasurement = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(sensors_filenames)) {
namePart <- unlist(strsplit(sensors_filenames[i], "\\."))[1]
highway <- unlist(strsplit(namePart, "_"))[2]
mId <- unlist(strsplit(namePart, "_"))[1]
name <- paste0(highway,"_",mId)
sensorVec <- c(sensorVec,name)
}
sensorVec <- unique(sensorVec)
sensorVec <- sort(sensorVec)
return(sensorVec)
}
GetRoadAndSensorNames()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
#libraries
require(XLConnect)
require(rmongodb)
require(futile.logger)
require(tm)
require(rmongodb)
require(RCurl)
require(jsonlite)
require(wordcloud)
require(RColorBrewer)
require(xts)
require(reshape2)
require(plyr)
require(ggplot2)
require(scales)
Sys.setenv(TZ='GMT')
# setwd("C:\\Users\\Ahmad\\Dropbox\\Work\\WolverhamptonUni\\Optimum\\social_media\\twitter\\SocialMinerShinyApp")
startStr <- "2016-07-01"
endStr <- "2016-07-05"
highwayCodes <- c("M1","M5")
plotHighwayTimeLines <- function(startStr, endStr, highwayCodes) {
if (length(highwayCodes) < 1) {
msg <- "highwayCodes must contains at least one highway"
return(msg)
}
startStr <- paste0(startStr,"T00:00:00")
endStr <- paste0(endStr,"T23:59:59")
startDt <-
strptime(startStr, format = "%Y-%m-%dT%H:%M:%S", tz = "GMT")
endDt <-
strptime(endStr, format = "%Y-%m-%dT%H:%M:%S", tz = "GMT")
if (endDt <= startStr) {
msg <- "start date must be older than end date"
return(msg)
}
#connect to mongoDB
mongo <- mongo.create(host = "optimum.euprojects.net:3368")
#create a list to store all the dataframes
highwayTwitterAggsList <- list()
if (mongo.is.connected(mongo) == TRUE) {
for (i in 1:length(highwayCodes)) {
#create dataframe to store the data
highwayTwitterAggs = data.frame(
gmt_date = as.POSIXct(character()),
value = numeric(0),
road = character(0),
stringsAsFactors = F
)
queryList <- mongo.bson.from.list(list(
'gmt_date' = list("$gte" = startDt,
"$lte" = endDt),
"highway_code" = highwayCodes[i]
))
tweets_count <-
mongo.count(mongo,"Twitter.uk_accounts_highway_hr_agg",query = queryList)
if (tweets_count > 0) {
# flog.info("Total records to be fetched for highway %s: %s",highwayCodes[i], tweets_count)
result <-
mongo.find(mongo, "Twitter.uk_accounts_highway_hr_agg", query = queryList)
while (mongo.cursor.next(result)) {
tdDt <- .POSIXct(character())
l <- list(mongo.bson.to.list(mongo.cursor.value(result)))
tdDt <- l[[1]]$gmt_date
value <- l[[1]]$value
highwayTwitterAggs <- rbind(
highwayTwitterAggs,
data.frame(
gmt_date = tdDt,
value = value,
road = highwayCodes[i],
stringsAsFactors = FALSE
)
)
}
attr(highwayTwitterAggs$gmt_date, "tzone") <- "GMT"
highwayTwitterAggs <-
highwayTwitterAggs[with(highwayTwitterAggs, order(gmt_date)),]
highwayTwitterAggsList[[i]] <- highwayTwitterAggs
} else {
#flog.info("No records found for highway %s",highwayCodes[i])
msg <- paste0("No records found for highway ",highwayCodes[i])
return(msg)
}
}
}
#Fill the hours which do not exist in the retrieved data with zero values
highwayTwitterAggsFullList <- list()
for (i in 1:length(highwayTwitterAggsList)) {
highwayTwitterAggsFull <- data.frame(
gmt_date = as.POSIXct(character()),
value = numeric(0),
road = character(0),
stringsAsFactors = F
)
highwayTwitterAggs <- highwayTwitterAggsList[[i]]
minDate <- startDt
maxDate <- endDt
road <- highwayTwitterAggs$road[1]
while (minDate <= maxDate) {
value <-
highwayTwitterAggs[highwayTwitterAggs$gmt_date == minDate,c("value")]
if (length(value) > 0) {
highwayTwitterAggsFull <- rbind(
highwayTwitterAggsFull,
data.frame(
gmt_date = minDate,
value = value,
road = road,
stringsAsFactors = FALSE
)
)
} else {
#         flog.info(
#           "No record found for highway %s on gmt_date: %s", road, strftime(minDate,"%Y-%m-%d %H:%M:%S",tz =
#                                                                              "GMT")
#         )
highwayTwitterAggsFull <- rbind(
highwayTwitterAggsFull,
data.frame(
gmt_date = minDate,
value = 0,
road = road,
stringsAsFactors = FALSE
)
)
}
minDate <- minDate + 3600
}
attr(highwayTwitterAggsFull$gmt_date, "tzone") <- "GMT"
highwayTwitterAggsFull <-
highwayTwitterAggsFull[with(highwayTwitterAggsFull, order(gmt_date)),]
highwayTwitterAggsFullList[[i]] <- highwayTwitterAggsFull
}
#create a dataframe of all the highway values
valuesDF <- NULL
for (i in 1:length(highwayTwitterAggsFullList)) {
highwayTwitterAggsFull <- highwayTwitterAggsFullList[[i]]
hway <- highwayTwitterAggsFull$road[1]
if (is.null(valuesDF)) {
valuesDF$col1 <- highwayTwitterAggsFull$value
valuesDF <- as.data.frame(valuesDF)
colnames(valuesDF) <- hway
} else {
col <- highwayTwitterAggsFull$value
col <- as.data.frame(col)
colnames(col) <- hway
valuesDF <- as.data.frame(cbind(valuesDF,col))
}
}
#create the melted dataframes and merge them all into one data frame for the plot
meltedDF <- data.frame(
gmt_date = as.POSIXct(character()),
variable = character(0),
value = numeric(0),
stringsAsFactors = F
)
for (i in 1:length(highwayTwitterAggsFullList)) {
highwayTwitterAggsFull <- highwayTwitterAggsFullList[[i]]
newdf <-
melt(highwayTwitterAggsFull[,c("gmt_date", "value")],'gmt_date')
newdf$variable <-
ifelse(newdf$variable == "value", highwayTwitterAggsFull$road[1], "value")
meltedDF <- rbind(meltedDF,newdf)
}
colnames(meltedDF) <- c("gmt_date", "Highway", "value")
attr(meltedDF$gmt_date, "tzone") <- "GMT"
lower <-
with(meltedDF,as.POSIXct(strftime(min(gmt_date),"%Y-%m-%d %H:%M:%S")))
upper <-
with(meltedDF,as.POSIXct(strftime(max(gmt_date),"%Y-%m-%d %H:%M:%S")))
limits = c(lower,upper)
timelineplot <- ggplot(meltedDF,aes(x = gmt_date,y = value)) +
geom_line(size = 1.5,aes(colour = Highway)) +
scale_fill_brewer(palette = "Set1") +
xlab("Time (Hours)") +
ylab("Number of tweets") +
scale_x_datetime(
date_breaks = ("2 hour"),
date_labels = "%b %d %H",
limits = limits
) +
scale_y_discrete(breaks = seq(min(meltedDF$value), max(meltedDF$value) *
2, by = 5), labels = comma) +
ggtitle("Highway Mentions in Tweets") +
theme(
axis.text.x = element_text(
angle = 45, hjust = 1, size = 8
),
axis.text.y = element_text(size = 10),
legend.text = element_text(size = 12)
)
returnList <- list()
returnList[[1]] <- timelineplot
returnList[[2]] <- valuesDF
return(returnList)
}
hlst <- plotHighwayTimeLines(startStr, endStr, highwayCodes)
hlst[[1]]
shiny::runApp()
